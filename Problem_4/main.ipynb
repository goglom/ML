{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import catboost\n",
    "\n",
    "from utils import serialize, deserialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(preds, gt):\n",
    "    rmse =  np.sqrt(mean_squared_error(preds, gt))\n",
    "    print('RMSE:', rmse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_scores = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"dataset/train.csv\")\n",
    "ds.drop(columns=[\"Id\"], inplace=True)\n",
    "\n",
    "cat_features = ds.select_dtypes(include = [\"object\"]).columns\n",
    "num_features = ds.select_dtypes(exclude = [\"object\"]).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PoolQC</th>\n",
       "      <td>1453</td>\n",
       "      <td>99.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MiscFeature</th>\n",
       "      <td>1406</td>\n",
       "      <td>96.301370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alley</th>\n",
       "      <td>1369</td>\n",
       "      <td>93.767123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fence</th>\n",
       "      <td>1179</td>\n",
       "      <td>80.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FireplaceQu</th>\n",
       "      <td>690</td>\n",
       "      <td>47.260274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageType</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageCond</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageQual</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GarageFinish</th>\n",
       "      <td>81</td>\n",
       "      <td>5.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtExposure</th>\n",
       "      <td>38</td>\n",
       "      <td>2.602740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtQual</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BsmtCond</th>\n",
       "      <td>37</td>\n",
       "      <td>2.534247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MasVnrType</th>\n",
       "      <td>8</td>\n",
       "      <td>0.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Electrical</th>\n",
       "      <td>1</td>\n",
       "      <td>0.068493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total          %\n",
       "PoolQC         1453  99.520548\n",
       "MiscFeature    1406  96.301370\n",
       "Alley          1369  93.767123\n",
       "Fence          1179  80.753425\n",
       "FireplaceQu     690  47.260274\n",
       "GarageType       81   5.547945\n",
       "GarageCond       81   5.547945\n",
       "GarageQual       81   5.547945\n",
       "GarageFinish     81   5.547945\n",
       "BsmtFinType2     38   2.602740\n",
       "BsmtExposure     38   2.602740\n",
       "BsmtFinType1     37   2.534247\n",
       "BsmtQual         37   2.534247\n",
       "BsmtCond         37   2.534247\n",
       "MasVnrType        8   0.547945\n",
       "Electrical        1   0.068493"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_nan_stat_table(dataset):\n",
    "    total = dataset.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "    percent = total / len(dataset) * 100\n",
    "    nan_stat_tbl = pd.concat([total, percent], axis=1, keys=['Total', '%'])\n",
    "    return nan_stat_tbl.loc[(nan_stat_tbl['%']>0)]\n",
    "\n",
    "get_nan_stat_table(ds[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset):\n",
    "    ds_new = dataset.drop(columns=[\"Id\"])\n",
    "\n",
    "    cat_features = ds_new.select_dtypes(include = [\"object\"]).columns\n",
    "    num_features = ds_new.select_dtypes(exclude = [\"object\"]).columns\n",
    "\n",
    "    ds_new[cat_features] = ds_new[cat_features].fillna('None')\n",
    "\n",
    "    for feature in num_features:\n",
    "        ds_new[feature] = ds_new[feature].fillna(ds_new[feature].mean())\n",
    "\n",
    "    return ds_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make categorical feature to numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_nocat = ds.copy()\n",
    "\n",
    "for feature in cat_features:\n",
    "    encoder = LabelEncoder()\n",
    "    encoded_feature = encoder.fit_transform(ds[feature])\n",
    "    ds_nocat[feature] = encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.log1p(ds.SalePrice.to_numpy())\n",
    "x = ds_nocat.drop(columns=[\"SalePrice\"]).to_numpy()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=98987)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=100; total time=   1.4s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=100; total time=   1.0s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=100; total time=   0.9s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=1000; total time=  10.6s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=1000; total time=   9.8s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=1000; total time=   9.5s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=1000; total time=   9.7s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=1, n_estimators=1000; total time=   9.6s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=100; total time=   0.8s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=100; total time=   0.7s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=1000; total time=   9.1s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=1000; total time=   7.9s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=1000; total time=   7.9s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=1000; total time=   8.0s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=2, n_estimators=1000; total time=   7.9s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=100; total time=   0.5s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=1000; total time=   5.6s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=1000; total time=   5.7s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=1000; total time=   5.6s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=1000; total time=   5.7s\n",
      "[CV] END criterion=squared_error, max_depth=1000, max_features=0.3333333333333333, min_samples_leaf=8, n_estimators=1000; total time=   7.1s\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'criterion':('squared_error',), \n",
    "    'max_depth': (1000,),\n",
    "    'max_features':(1/3, ),\n",
    "    'n_estimators': (100, 1000),\n",
    "    'min_samples_leaf': (1, 2, 8)\n",
    "}\n",
    "\n",
    "rforest = RandomForestRegressor()\n",
    "rforest_gs = GridSearchCV(rforest, parameters, verbose=2)\n",
    "rforest_gs.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize(rforest_gs, \"rforest_gs\")\n",
    "serialize(rforest, \"rforest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rforest_gs = deserialize(\"rforest_gs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'squared_error', 'max_depth': 1000, 'max_features': 0.3333333333333333, 'min_samples_leaf': 1, 'n_estimators': 1000}\n",
      "RMSE: 0.1553235616691357\n"
     ]
    }
   ],
   "source": [
    "print(rforest_gs.best_params_)\n",
    "best_scores[\"RandomForest\"] = show_results(rforest_gs.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=1000; total time=   3.3s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=1000; total time=   1.9s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=1000; total time=   1.7s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=5000; total time=   8.9s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=5000; total time=   9.0s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=1, n_estimators=5000; total time=   8.9s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=10, n_estimators=1000; total time=   1.5s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=10, n_estimators=1000; total time=   1.6s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=10, n_estimators=1000; total time=   1.6s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=10, n_estimators=5000; total time=   8.4s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=10, n_estimators=5000; total time=   8.6s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=2, min_child_weight=10, n_estimators=5000; total time=   8.3s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000; total time=   1.6s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000; total time=   1.5s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=1000; total time=   1.7s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=5000; total time=  13.1s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=5000; total time=  12.9s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=1, n_estimators=5000; total time=  14.0s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=10, n_estimators=1000; total time=   1.6s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=10, n_estimators=1000; total time=   1.5s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=10, n_estimators=1000; total time=   1.5s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=10, n_estimators=5000; total time=  12.1s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=10, n_estimators=5000; total time=  20.7s\n",
      "[CV] END gamma=0.0, learning_rate=0.001, max_depth=4, min_child_weight=10, n_estimators=5000; total time=  14.9s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=1000; total time=   1.9s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=1000; total time=   1.6s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=1000; total time=   1.7s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=5000; total time=   8.3s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=5000; total time=   8.9s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=1, n_estimators=5000; total time=   8.3s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=10, n_estimators=1000; total time=   1.7s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=10, n_estimators=1000; total time=   2.5s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=10, n_estimators=1000; total time=   2.3s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=10, n_estimators=5000; total time=   8.0s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=10, n_estimators=5000; total time=   7.8s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=2, min_child_weight=10, n_estimators=5000; total time=   7.6s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000; total time=   2.5s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000; total time=   2.4s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=1000; total time=   2.3s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=5000; total time=  13.4s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=5000; total time=  14.8s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=1, n_estimators=5000; total time=  14.2s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=1000; total time=   2.2s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=1000; total time=   2.5s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=1000; total time=   2.8s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=5000; total time=  14.7s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=5000; total time=  12.8s\n",
      "[CV] END gamma=0.0, learning_rate=0.01, max_depth=4, min_child_weight=10, n_estimators=5000; total time=  16.0s\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"learning_rate\": (0.001, 0.01, ),\n",
    "    \"max_depth\": [ 2, 4],\n",
    "    \"min_child_weight\": [ 1, 10],\n",
    "    \"gamma\":[ 0.0,],\n",
    "    \"n_estimators\": [1000, 5000]\n",
    "}\n",
    "xgb = xgboost.XGBRegressor()\n",
    "xgb_gs = GridSearchCV(xgb, parameters, verbose=2, cv=3)\n",
    "xgb_gs.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize(xgb_gs, \"xgb_gs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_gs = deserialize(\"xgb_gs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0, 'learning_rate': 0.01, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 5000}\n",
      "RMSE: 0.12810969890915763\n"
     ]
    }
   ],
   "source": [
    "print(xgb_gs.best_params_)\n",
    "best_scores[\"XGBoost\"] = show_results(xgb_gs.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'num_leaves': (40, 20, 10,),\n",
    "    'learning_rate': (0.1, 0.01, 0.05),\n",
    "    'max_depth': (-1,),\n",
    "    'n_estimators': (10**3, 10**4),}\n",
    "\n",
    "lgbmr_gs = GridSearchCV(LGBMRegressor(), parameters, verbose=2)\n",
    "lgbmr_gs.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize(lgbmr_gs, \"lgbmr_gs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbmr_gs = deserialize(\"lgbmr_gs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': -1, 'n_estimators': 1000, 'num_leaves': 10}\n",
      "RMSE: 0.1409159071922352\n"
     ]
    }
   ],
   "source": [
    "print(lgbmr_gs.best_params_)\n",
    "best_scores[\"LightGBM\"] = show_results(lgbmr_gs.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бустинг минимизирует как смещение (bias) так и расброс (variance)\n",
    "Бэггинг уменьшает только разброс(((("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cat Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) В качестве базового алгоритма используются небрежные решающие деревья (ODT - Obvious Decision Tree)\n",
    "2) В качестве метода ансаблированния используется модифицированный градиентный бустинг. Суть его следующая:\n",
    "   * Перед обучением создаётся s перестановок обучающей выборки $X_1, X_2, ..., X_s$. \n",
    "   * Кадая из этих перестановок $X_\\sigma$ делится на части, длина которых возрастает в геометрической прогрессии ($2^i$). \n",
    "   * Каждый новый алгоритм ансамбля $b_t$ строится на перстановке $X_\\sigma$, где $\\sigma$ выбирается случайным образом от 0 до s\n",
    "   * $$b_t := \\arg\\min_b\\sum_{i=1}^{l}{(b(x_i) + g_{ti})^2}$$\n",
    "   * Градиент $g_{ti}$ вычисляется по выборке $X^{\\sigma j}$, где j - это подвыборка перстановки в которой не учасвствовал объект $x_i$\n",
    "   * $$g_{t i} = \\mathcal{L}'(a^{r j}_{t-1}(x_i), y_i) $$\n",
    "   * $$j = \\log_2(i - 1)$$\n",
    "3) Следующая фича - работа с категориальными признаками. Категориальные признаки преобразуются в вещественные с помощью метода статистики по целевому признаку (TS).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ds.drop(columns=['SalePrice'])\n",
    "y = np.log1p(ds['SalePrice'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=98987)\n",
    "\n",
    "\n",
    "train_pool = catboost.Pool(x_train, y_train, cat_features=cat_features.tolist())\n",
    "test_pool = catboost.Pool(x_test, y_test, cat_features=cat_features.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1426659313\n",
      "bestIteration = 976\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1228953334\n",
      "bestIteration = 997\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1428224128\n",
      "bestIteration = 489\n",
      "\n",
      "0:\tloss: 0.1364070\tbest: 0.1364070 (0)\ttotal: 24.9s\tremaining: 7m 3s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1468508741\n",
      "bestIteration = 515\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1287590721\n",
      "bestIteration = 330\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1426366063\n",
      "bestIteration = 573\n",
      "\n",
      "1:\tloss: 0.1427930\tbest: 0.1364070 (0)\ttotal: 45.7s\tremaining: 6m 5s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1433343056\n",
      "bestIteration = 969\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1237657549\n",
      "bestIteration = 980\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1428005309\n",
      "bestIteration = 434\n",
      "\n",
      "2:\tloss: 0.1368443\tbest: 0.1364070 (0)\ttotal: 1m 3s\tremaining: 5m 16s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1481568056\n",
      "bestIteration = 385\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1292779143\n",
      "bestIteration = 401\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1433506445\n",
      "bestIteration = 250\n",
      "\n",
      "3:\tloss: 0.1434641\tbest: 0.1364070 (0)\ttotal: 1m 21s\tremaining: 4m 44s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1435380901\n",
      "bestIteration = 984\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1237907319\n",
      "bestIteration = 995\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1421730288\n",
      "bestIteration = 973\n",
      "\n",
      "4:\tloss: 0.1365842\tbest: 0.1364070 (0)\ttotal: 1m 43s\tremaining: 4m 28s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1510391809\n",
      "bestIteration = 415\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1267968245\n",
      "bestIteration = 557\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1437002402\n",
      "bestIteration = 179\n",
      "\n",
      "5:\tloss: 0.1448083\tbest: 0.1364070 (0)\ttotal: 2m\tremaining: 4m\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1401627957\n",
      "bestIteration = 998\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1249899888\n",
      "bestIteration = 647\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1366015311\n",
      "bestIteration = 858\n",
      "\n",
      "6:\tloss: 0.1343853\tbest: 0.1343853 (6)\ttotal: 2m 46s\tremaining: 4m 22s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1643624728\n",
      "bestIteration = 262\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1547738133\n",
      "bestIteration = 382\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1699072662\n",
      "bestIteration = 68\n",
      "\n",
      "7:\tloss: 0.1691524\tbest: 0.1343853 (6)\ttotal: 3m 34s\tremaining: 4m 27s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1375661337\n",
      "bestIteration = 957\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.124870185\n",
      "bestIteration = 648\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.134575613\n",
      "bestIteration = 998\n",
      "\n",
      "8:\tloss: 0.1325391\tbest: 0.1325391 (8)\ttotal: 4m 34s\tremaining: 4m 34s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1492558063\n",
      "bestIteration = 84\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1764223574\n",
      "bestIteration = 234\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1649038713\n",
      "bestIteration = 103\n",
      "\n",
      "9:\tloss: 0.1721870\tbest: 0.1325391 (8)\ttotal: 5m 40s\tremaining: 4m 32s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1394740738\n",
      "bestIteration = 875\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1280864547\n",
      "bestIteration = 979\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1404329302\n",
      "bestIteration = 915\n",
      "\n",
      "10:\tloss: 0.1362873\tbest: 0.1325391 (8)\ttotal: 6m 31s\tremaining: 4m 9s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.152685893\n",
      "bestIteration = 107\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.150749889\n",
      "bestIteration = 296\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1730439778\n",
      "bestIteration = 739\n",
      "\n",
      "11:\tloss: 0.1633103\tbest: 0.1325391 (8)\ttotal: 7m 33s\tremaining: 3m 46s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1510167731\n",
      "bestIteration = 962\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1275494747\n",
      "bestIteration = 787\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1401435209\n",
      "bestIteration = 793\n",
      "\n",
      "12:\tloss: 0.1400821\tbest: 0.1325391 (8)\ttotal: 9m 3s\tremaining: 3m 28s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1929723738\n",
      "bestIteration = 84\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1592119443\n",
      "bestIteration = 63\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1528196564\n",
      "bestIteration = 48\n",
      "\n",
      "13:\tloss: 0.1789801\tbest: 0.1325391 (8)\ttotal: 10m 34s\tremaining: 3m 1s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1532823528\n",
      "bestIteration = 998\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.133557121\n",
      "bestIteration = 687\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1397525775\n",
      "bestIteration = 586\n",
      "\n",
      "14:\tloss: 0.1427007\tbest: 0.1325391 (8)\ttotal: 12m 7s\tremaining: 2m 25s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1934338042\n",
      "bestIteration = 21\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.2012695411\n",
      "bestIteration = 52\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1737525599\n",
      "bestIteration = 43\n",
      "\n",
      "15:\tloss: 0.1978420\tbest: 0.1325391 (8)\ttotal: 13m 35s\tremaining: 1m 41s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.1534380426\n",
      "bestIteration = 934\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.1361044464\n",
      "bestIteration = 962\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1413464857\n",
      "bestIteration = 729\n",
      "\n",
      "16:\tloss: 0.1438842\tbest: 0.1325391 (8)\ttotal: 15m 6s\tremaining: 53.3s\n",
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.2175419063\n",
      "bestIteration = 37\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.209118085\n",
      "bestIteration = 121\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.1820890395\n",
      "bestIteration = 38\n",
      "\n",
      "17:\tloss: 0.2081495\tbest: 0.1325391 (8)\ttotal: 16m 33s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "p_grid = {\n",
    "        'learning_rate': [0.07, 0.9],\n",
    "        'depth': [1, 2, 3],\n",
    "        'l2_leaf_reg': [0.7, 1, 1.3],\n",
    "}\n",
    "\n",
    "catboost_cls = CatBoostRegressor(\n",
    "        loss_function='RMSE',\n",
    "        verbose=0\n",
    ")\n",
    "grid_search_results = catboost_cls.grid_search(p_grid, train_pool, shuffle=False, verbose=1, search_by_train_test_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize(catboost_cls, \"catboost_cls\")\n",
    "serialize(grid_search_results, \"grid_search_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1282228211514425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1282228211514425"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_results(catboost_cls.predict(test_pool), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make submission for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = pd.read_csv('dataset/test.csv')\n",
    "test_ds = prepare_dataset(test_ds)\n",
    "cat_features = test_ds.select_dtypes(['object']).columns.tolist()\n",
    "\n",
    "y_pred = catboost_cls.predict(test_ds)\n",
    "#return y's to original space\n",
    "y_pred = np.expm1(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission = pd.read_csv('dataset/sample_submission.csv')\n",
    "my_submission['SalePrice'] = y_pred\n",
    "\n",
    "my_submission.to_csv('my_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb3c2a364b214c6ffe2642e853d25ce1e83d451a57eea557fd0e3e886ac6e718"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
